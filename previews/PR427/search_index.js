var documenterSearchIndex = {"docs":
[{"location":"types/#Types-API","page":"Types API","title":"Types API","text":"This page includes docstrings for some types defined in Bijectors.","category":"section"},{"location":"types/#General-types","page":"Types API","title":"General types","text":"","category":"section"},{"location":"types/#Specific-bijectors","page":"Types API","title":"Specific bijectors","text":"","category":"section"},{"location":"types/#Bijectors.Transform","page":"Types API","title":"Bijectors.Transform","text":"Abstract type for a transformation.\n\nImplementing\n\nA subtype of Transform of should at least implement transform(b, x).\n\nIf the Transform is also invertible:\n\nRequired:\nEither of the following:\ntransform(::Inverse{<:MyTransform}, x): the transform for its inverse.\nInverseFunctions.inverse(b::MyTransform): returns an existing Transform.\nlogabsdetjac: computes the log-abs-det jacobian factor.\nOptional:\nwith_logabsdet_jacobian: transform and logabsdetjac combined. Useful in cases where we can exploit shared computation in the two.\n\nFor the above methods, there are mutating versions which can optionally be implemented:\n\nwith_logabsdet_jacobian!\nlogabsdetjac!\nwith_logabsdet_jacobian!\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.Bijector","page":"Types API","title":"Bijectors.Bijector","text":"Abstract type of a bijector, i.e. differentiable bijection with differentiable inverse.\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.Inverse","page":"Types API","title":"Bijectors.Inverse","text":"inverse(b::Transform)\nInverse(b::Transform)\n\nA Transform representing the inverse transform of b.\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.CorrBijector","page":"Types API","title":"Bijectors.CorrBijector","text":"CorrBijector <: Bijector\n\nA bijector implementation of Stan's parametrization method for Correlation matrix: https://mc-stan.org/docs/reference-manual/transforms.html#correlation-matrix-transform.section\n\nBasically, a unconstrained strictly upper triangular matrix y is transformed to  a correlation matrix by following readable but not that efficient form:\n\nK = size(y, 1)\nz = tanh.(y)\n\nfor j=1:K, i=1:K\n    if i>j\n        w[i,j] = 0\n    elseif 1==i==j\n        w[i,j] = 1\n    elseif 1<i==j\n        w[i,j] = prod(sqrt(1 .- z[1:i-1, j].^2))\n    elseif 1==i<j\n        w[i,j] = z[i,j]\n    elseif 1<i<j\n        w[i,j] = z[i,j] * prod(sqrt(1 .- z[1:i-1, j].^2))\n    end\nend\n\nIt is easy to see that every column is a unit vector, for example:\n\nw3' w3 ==\nw[1,3]^2 + w[2,3]^2 + w[3,3]^2 ==\nz[1,3]^2 + (z[2,3] * sqrt(1 - z[1,3]^2))^2 + (sqrt(1-z[1,3]^2) * sqrt(1-z[2,3]^2))^2 ==\nz[1,3]^2 + z[2,3]^2 * (1-z[1,3]^2) + (1-z[1,3]^2) * (1-z[2,3]^2) ==\nz[1,3]^2 + z[2,3]^2 - z[2,3]^2 * z[1,3]^2 + 1 -z[1,3]^2 - z[2,3]^2 + z[1,3]^2 * z[2,3]^2 ==\n1\n\nAnd diagonal elements are positive, so w is a cholesky factor for a positive matrix.\n\nx = w' * w\n\nConsider block matrix representation for x\n\nx = [w1'; w2'; ... wn'] * [w1 w2 ... wn] == \n[w1'w1 w1'w2 ... w1'wn;\n w2'w1 w2'w2 ... w2'wn;\n ...\n]\n\nThe diagonal elements are given by wk'wk = 1, thus x is a correlation matrix.\n\nEvery step is invertible, so this is a bijection(bijector).\n\nNote: The implementation doesn't follow their \"manageable expression\" directly, because their equation seems wrong (7/30/2020). Insteadly it follows definition  above the \"manageable expression\" directly, which is also described in above doc.\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.LeakyReLU","page":"Types API","title":"Bijectors.LeakyReLU","text":"LeakyReLU{T}(Œ±::T) <: Bijector\n\nDefines the invertible mapping\n\nx ‚Ü¶ x if x ‚â• 0 else Œ±x\n\nwhere Œ± > 0.\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.Stacked","page":"Types API","title":"Bijectors.Stacked","text":"Stacked(bs)\nStacked(bs, ranges)\nStacked(bs::Bijector...)\n\nA Bijector which stacks bijectors together which can then be applied to a vector where bs[i]::Bijector is applied to x[ranges[i]]::UnitRange{Int}.\n\nArguments\n\nbs can be either a Tuple or an AbstractArray of 0- and/or 1-dimensional bijectors\nIf bs is a Tuple, implementations are type-stable using generated functions\nIf bs is an AbstractArray, implementations are not type-stable and use iterative methods\nranges needs to be an iterable consisting of UnitRange{Int}\nlength(bs) == length(ranges) needs to be true.\n\nExamples\n\nusing Bijectors: Logit, Stacked\nb1 = Logit(0.0, 1.0)\nb2 = identity\nb = Stacked(b1, b2)\nb([0.0, 1.0]) == [b1(0.0), 1.0]  # => true\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.RationalQuadraticSpline","page":"Types API","title":"Bijectors.RationalQuadraticSpline","text":"RationalQuadraticSpline{T} <: Bijector\n\nImplementation of the Rational Quadratic Spline flow [1].\n\nOutside of the interval [minimum(widths), maximum(widths)], this mapping is given  by the identity map. \nInside the interval it's given by a monotonic spline (i.e. monotonic polynomials  connected at intermediate points) with endpoints fixed so as to continuously transform into the identity map.\n\nFor the sake of efficiency, there are separate implementations for 0-dimensional and 1-dimensional inputs.\n\nNotes\n\nThere are two constructors for RationalQuadraticSpline:\n\nRationalQuadraticSpline(widths, heights, derivatives): it is assumed that widths, \n\nheights, and derivatives satisfy the constraints that makes this a valid bijector, i.e.\n\nwidths: monotonically increasing and length(widths) == K,\nheights: monotonically increasing and length(heights) == K,\nderivatives: non-negative and derivatives[1] == derivatives[end] == 1.\nRationalQuadraticSpline(widths, heights, derivatives, B): other than than the lengths,  no assumptions are made on parameters. Therefore we will transform the parameters s.t.:\nwidths_new ‚àà [-B, B]·¥∑‚Å∫¬π, where K == length(widths),\nheights_new ‚àà [-B, B]·¥∑‚Å∫¬π, where K == length(heights),\nderivatives_new ‚àà (0, ‚àû)·¥∑‚Å∫¬π with derivatives_new[1] == derivates_new[end] == 1,  where (K - 1) == length(derivatives).\n\nExamples\n\nUnivariate\n\njulia> using StableRNGs: StableRNG; rng = StableRNG(42);  # For reproducibility.\n\njulia> using Bijectors: RationalQuadraticSpline\n\njulia> K = 3; B = 2;\n\njulia> # Monotonic spline on '[-B, B]' with `K` intermediate knots/\"connection points\".\n       b = RationalQuadraticSpline(randn(rng, K), randn(rng, K), randn(rng, K - 1), B);\n\njulia> b(0.5) # inside of `[-B, B]` ‚Üí transformed\n1.1943325397834206\n\njulia> b(5.) # outside of `[-B, B]` ‚Üí not transformed\n5.0\n\njulia> b = RationalQuadraticSpline(b.widths, b.heights, b.derivatives);\n\njulia> b(0.5) # inside of `[-B, B]` ‚Üí transformed\n1.1943325397834206\n\njulia> d = 2; K = 3; B = 2;\n\njulia> b = RationalQuadraticSpline(randn(rng, d, K), randn(rng, d, K), randn(rng, d, K - 1), B);\n\njulia> b([-1., 1.])\n2-element Vector{Float64}:\n -1.5660106244288925\n  0.5384702734738573\n\njulia> b([-5., 5.])\n2-element Vector{Float64}:\n -5.0\n  5.0\n\njulia> b([-1., 5.])\n2-element Vector{Float64}:\n -1.5660106244288925\n  5.0\n\nReferences\n\n[1] Durkan, C., Bekasov, A., Murray, I., & Papamakarios, G., Neural Spline Flows, CoRR, arXiv:1906.04032 [stat.ML],  (2019). \n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.Coupling","page":"Types API","title":"Bijectors.Coupling","text":"Coupling{F, M}(Œ∏::F, mask::M)\n\nImplements a coupling-layer as defined in [1].\n\nExamples\n\njulia> using Bijectors: Shift, Coupling, PartitionMask, coupling, couple\n\njulia> m = PartitionMask(3, [1], [2]); # <= going to use x[2] to parameterize transform of x[1]\n\njulia> cl = Coupling(Shift, m); # <= will do `y[1:1] = x[1:1] + x[2:2]`;\n\njulia> x = [1., 2., 3.];\n\njulia> cl(x)\n3-element Vector{Float64}:\n 3.0\n 2.0\n 3.0\n\njulia> inverse(cl)(cl(x))\n3-element Vector{Float64}:\n 1.0\n 2.0\n 3.0\n\njulia> coupling(cl) # get the `Bijector` map `Œ∏ -> b(‚ãÖ, Œ∏)`\nShift\n\njulia> couple(cl, x) # get the `Bijector` resulting from `x`\nShift{Vector{Float64}}([2.0])\n\njulia> with_logabsdet_jacobian(cl, x)\n([3.0, 2.0, 3.0], 0.0)\n\nReferences\n\n[1] Kobyzev, I., Prince, S., & Brubaker, M. A., Normalizing flows: introduction and ideas, CoRR, (),  (2019). \n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.OrderedBijector","page":"Types API","title":"Bijectors.OrderedBijector","text":"OrderedBijector()\n\nA bijector mapping unordered vectors in ‚Ñù·µà to ordered vectors in ‚Ñù·µà.\n\nSee also\n\nStan's documentation\nNote that this transformation and its inverse are the opposite of in this reference.\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.NamedTransform","page":"Types API","title":"Bijectors.NamedTransform","text":"NamedTransform <: AbstractNamedTransform\n\nWraps a NamedTuple of key -> Bijector pairs, implementing evaluation, inversion, etc.\n\nExamples\n\njulia> using Bijectors: NamedTransform, Scale\n\njulia> b = NamedTransform((a = Scale(2.0), b = exp));\n\njulia> x = (a = 1., b = 0., c = 42.);\n\njulia> b(x)\n(a = 2.0, b = 1.0, c = 42.0)\n\njulia> (a = 2 * x.a, b = exp(x.b), c = x.c)\n(a = 2.0, b = 1.0, c = 42.0)\n\n\n\n\n\n","category":"type"},{"location":"types/#Bijectors.NamedCoupling","page":"Types API","title":"Bijectors.NamedCoupling","text":"NamedCoupling{target, deps, F} <: AbstractNamedTransform\n\nImplements a coupling layer for named bijectors.\n\nSee also: Coupling\n\nExamples\n\njulia> using Bijectors: NamedCoupling, Scale\n\njulia> b = NamedCoupling(:b, (:a, :c), (a, c) -> Scale(a + c));\n\njulia> x = (a = 1., b = 2., c = 3.);\n\njulia> b(x)\n(a = 1.0, b = 8.0, c = 3.0)\n\njulia> (a = x.a, b = (x.a + x.c) * x.b, c = x.c)\n(a = 1.0, b = 8.0, c = 3.0)\n\n\n\n\n\n","category":"type"},{"location":"flows/#Example:-Normalizing-flows","page":"Example: Normalizing flows","title":"Example: Normalizing flows","text":"A very interesting application of bijectors is in normalizing flows. Usually this is done by sampling from a multivariate normal distribution, and then transforming this to a target distribution using invertible neural networks. Currently there are two such transforms available in Bijectors.jl: PlanarLayer and RadialLayer. Let's create a flow with a single PlanarLayer:\n\nusing Bijectors\nusing StableRNGs: StableRNG\nrng = StableRNG(42)\n\nd = MvNormal(zeros(2), ones(2))\nb = PlanarLayer(2)\nflow = transformed(d, b)\n\nflow is itself a multivariate distribution, so we can sample from it using rand and compute the logpdf, like any other Distribution.\n\ny = rand(rng, flow)\nlogpdf(flow, y)         # uses inverse of `b`\n\nSimilarily to the multivariate ADVI example, we could use Stacked to get a bounded flow:\n\nd = MvNormal(zeros(2), ones(2));\nibs = inverse.(bijector.((InverseGamma(2, 3), Beta())));\nsb = Stacked(ibs) # == Stacked(ibs, [i:i for i = 1:length(ibs)]\nb = sb ‚àò PlanarLayer(2)\ntd = transformed(d, b);\ny = rand(rng, td)\n\n(As required, we have that 0 < y[1] and 0 ‚â§ y[2] ‚â§ 1.)\n\nTo fit the flow, we can define an objective function that computes the negative log-likelihood of some data. We will need to use automatic differentiation to compute gradients of the objective with respect to the parameters. Since most AD packages require vectorised inputs, this means we also need a way to convert between the vectorised parameters and the PlanarLayer struct.\n\nusing ForwardDiff\n\n# Construct the flow.\nb = PlanarLayer(2)\n\n# Obtain a vectorised version of the parameters.\nxs_init = vcat(b.w, b.u, b.b)\n\n# Function to reconstruct the `PlanarLayer` from vectorised parameters.\nfunction reconstruct_planarlayer(xs::AbstractVector)\n    dim = 2\n    w = xs[1:dim]\n    u = xs[(dim + 1):(2 * dim)]\n    b = xs[end:end]\n    return PlanarLayer(w, u, b)\nend\n\n# Check that the reconstruction does work...\nreconstruct_planarlayer(xs_init) == b\n\nHere is the objective function:\n\n# Make the objective a `struct` to avoid capturing global variables.\nstruct NLLObjective{R,D,T}\n    reconstruct::R\n    basedist::D\n    data::T\nend\n\nfunction (obj::NLLObjective)(xs::AbstractVector)\n    transformed_dist = transformed(obj.basedist, obj.reconstruct(xs))\n    return -sum(Base.Fix1(logpdf, transformed_dist), eachcol(obj.data))\nend\n\n# Some random data to estimate the density of.\nxs = randn(2, 1000)\n\n# Construct the objective.\nf = NLLObjective(reconstruct_planarlayer, MvNormal(2, 1), xs)\n\nprintln(\"Initial loss = $(f(xs_init)) at xs_init = $(xs_init)\")\n\nNow we can train the flow using gradient descent:\n\nusing ForwardDiff: ForwardDiff\n\nfunction train(xs_init, niters; stepsize=1e-3)\n    xs = xs_init\n    for i in 1:niters\n        grad = ForwardDiff.gradient(f, xs)\n        @. xs = xs - (stepsize * grad)\n    end\n    return xs\nend\nxs_trained = train(xs_init, 1000)\n\nprintln(\"Final loss = $(f(xs_trained)) at xs_trained = $(xs_trained)\")\n\nFinally, we can sample from the trained flow and check that the samples have approximately zero mean and identity covariance (as expected given that our data was sampled using randn):\n\nsamples = rand(transformed(f.basedist, f.reconstruct(xs_trained)), 1000);\n\n# mean ‚âà [0, 0], cov ‚âà I\nmean(eachcol(samples)), cov(samples; dims=2)\n\nMore complex flows can be created by composing multiple layers, e.g. PlanarLayer(10) ‚àò PlanarLayer(10) ‚àò RadialLayer(10).","category":"section"},{"location":"interface/#Interface","page":"Interface","title":"Interface","text":"This page describes the user-facing interface of Bijectors.jl. You should be able to use all the functions documented here with any bijector defined in Bijectors.jl.","category":"section"},{"location":"interface/#Transformation","page":"Interface","title":"Transformation","text":"Bijectors are also callable objects, so b(x) is equivalent to transform(b, x).","category":"section"},{"location":"interface/#Inverses","page":"Interface","title":"Inverses","text":"","category":"section"},{"location":"interface/#Log-absolute-determinant-of-the-Jacobian","page":"Interface","title":"Log-absolute determinant of the Jacobian","text":"","category":"section"},{"location":"interface/#Transform-wrappers","page":"Interface","title":"Transform wrappers","text":"","category":"section"},{"location":"interface/#Elementwise-transformation","page":"Interface","title":"Elementwise transformation","text":"Some transformations are well-defined for different types of inputs, e.g. exp can also act elementwise on an N-dimensional Array{<:Real,N}. To specify that a transformation should act elementwise, we can wrap it in the elementwise wrapper:","category":"section"},{"location":"interface/#Columnwise-transformation","page":"Interface","title":"Columnwise transformation","text":"Likewise:","category":"section"},{"location":"interface/#Working-with-distributions","page":"Interface","title":"Working with distributions","text":"","category":"section"},{"location":"interface/#Utilities","page":"Interface","title":"Utilities","text":"","category":"section"},{"location":"interface/#Bijectors.transform","page":"Interface","title":"Bijectors.transform","text":"transform(b, x)\n\nTransform x using b.\n\nIf with_logabsdet_jacobian is already implemented for b, the default implementation of transform will call first(with_logabsdet_jacobian(b, x)).\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.transform!","page":"Interface","title":"Bijectors.transform!","text":"transform!(b, x[, y])\n\nTransform x using b, storing the result in y.\n\nIf y is not provided, x is used as the output.\n\n\n\n\n\n","category":"function"},{"location":"interface/#InverseFunctions.inverse","page":"Interface","title":"InverseFunctions.inverse","text":"inverse(t::Transform)\n\nReturns the inverse of transform t.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.logabsdetjac","page":"Interface","title":"Bijectors.logabsdetjac","text":"logabsdetjac(b, x)\n\nReturn log(abs(det(J(b, x)))), where J(b, x) is the jacobian of b at x.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.logabsdetjac!","page":"Interface","title":"Bijectors.logabsdetjac!","text":"logabsdetjac!(b, x[, logjac])\n\nCompute log(abs(det(J(b, x)))) and store the result in logjac, where J(b, x) is the jacobian of b at x.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.logabsdetjacinv","page":"Interface","title":"Bijectors.logabsdetjacinv","text":"logabsdetjacinv(b, y)\n\nJust an alias for logabsdetjac(inverse(b), y).\n\n\n\n\n\n","category":"function"},{"location":"interface/#ChangesOfVariables.with_logabsdet_jacobian","page":"Interface","title":"ChangesOfVariables.with_logabsdet_jacobian","text":"with_logabsdet_jacobian(t::Transform, x)\n\nSemantically, this must return a tuple of (y, logabsdetjac), where y = transform(t, x) and logabsdetjac = logabsdetjac(t, x). However, you can implement this function to exploit shared computation between the two quantities.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.with_logabsdet_jacobian!","page":"Interface","title":"Bijectors.with_logabsdet_jacobian!","text":"with_logabsdet_jacobian!(b, x[, y, logjac])\n\nCompute transform(b, x) and logabsdetjac(b, x), storing the result in y and logjac, respetively.\n\nIf y is not provided, then x will be used in its place.\n\nDefaults to calling with_logabsdet_jacobian(b, x) and updating y and logjac with the result.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.elementwise","page":"Interface","title":"Bijectors.elementwise","text":"elementwise(f)\n\nAlias for Base.Fix1(broadcast, f).\n\nIn the case where f::ComposedFunction, the result is Base.Fix1(broadcast, f.outer) ‚àò Base.Fix1(broadcast, f.inner) rather than Base.Fix1(broadcast, f).\n\nExamples\n\njulia> x = [1.0, 2.0, 3.0];\n\njulia> f = elementwise(exp);\n\njulia> f(x)\n3-element Vector{Float64}:\n  2.718281828459045\n  7.38905609893065\n 20.085536923187668\n\njulia> with_logabsdet_jacobian(f, x)\n([2.718281828459045, 7.38905609893065, 20.085536923187668], 6.0)\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.columnwise","page":"Interface","title":"Bijectors.columnwise","text":"columnwise(f)\n\nAlias for Base.Fix1(eachcolmaphcat, f).\n\nRepresents a function f which is applied to each column of an input.\n\nExamples\n\njulia> x = [4.0 5.0 6.0; 1.0 2.0 3.0];\n\njulia> my_reverse(v) = reverse(v);  # To avoid type piracy.\n\njulia> f = columnwise(my_reverse);\n\njulia> f(x)\n2√ó3 Matrix{Float64}:\n 1.0  2.0  3.0\n 4.0  5.0  6.0\n\njulia> # We can't use `with_logabsdet_jacobian` on `f` until we define it\n       # for `my_reverse`, since we need to sum over columns.\n       Bijectors.with_logabsdet_jacobian(::typeof(my_reverse), xs) = my_reverse(xs), 0.0;\n\njulia> with_logabsdet_jacobian(f, x)\n([1.0 2.0 3.0; 4.0 5.0 6.0], 0.0)\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.bijector","page":"Interface","title":"Bijectors.bijector","text":"bijector(d::Distribution)\n\nReturns the constrained-to-unconstrained bijector for distribution d.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.link","page":"Interface","title":"Bijectors.link","text":"link(d::Distribution, x)\n\nTransforms the input x using the constrained-to-unconstrained bijector for distribution d.\n\nSee also: invlink.\n\nExample\n\njulia> using Bijectors\n\njulia> d = LogNormal()   # support is (0, Inf)\nLogNormal{Float64}(Œº=0.0, œÉ=1.0)\n\njulia> b = bijector(d)   # log function transforms to unconstrained space\n(::Base.Fix1{typeof(broadcast), typeof(log)}) (generic function with 2 methods)\n\njulia> b(1.0)\n0.0\n\njulia> link(LogNormal(), 1.0)\n0.0\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.invlink","page":"Interface","title":"Bijectors.invlink","text":"invlink(d::Distribution, y)\n\nPerforms the inverse transform on a value y that was transformed using the constrained-to-unconstrained bijector for distribution d.\n\nIt should hold that invlink(d, link(d, x)) = x.\n\nSee also: link.\n\nExample\n\njulia> using Bijectors\n\njulia> d = LogNormal()    # support is (0, Inf)\nLogNormal{Float64}(Œº=0.0, œÉ=1.0)\n\njulia> link(LogNormal(), 1.0)   # uses a log transform\n0.0\n\njulia> invlink(LogNormal(), 0.0)\n1.0\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.logpdf_with_trans","page":"Interface","title":"Bijectors.logpdf_with_trans","text":"logpdf_with_trans(d::Distribution, x, transform::Bool)\n\nIf transform is false, logpdf_with_trans calculates the log probability density function (logpdf) of distribution d at x.\n\nIf transform is true, x is transformed using the constrained-to-unconstrained bijector for distribution d, and then the logpdf of the resulting value is calculated with respect to the unconstrained (transformed) distribution. Equivalently, if x is distributed according to d and y = link(d, x) is distributed according to td = transformed(d), then logpdf_with_trans(d, x, true) = logpdf(td, y). This is accomplished by subtracting the log Jacobian of the transformation.\n\nExample\n\njulia> using Bijectors\n\njulia> logpdf_with_trans(LogNormal(), ‚ÑØ, false)\n-2.4189385332046727\n\njulia> logpdf(LogNormal(), ‚ÑØ)  # Same as above\n-2.4189385332046727\n\njulia> logpdf_with_trans(LogNormal(), ‚ÑØ, true)\n-1.4189385332046727\n\njulia> # If x ~ LogNormal(), then log(x) ~ Normal()\n       logpdf(Normal(), 1.0)   \n-1.4189385332046727\n\njulia> # The difference between the two is due to the Jacobian\n       logabsdetjac(bijector(LogNormal()), ‚ÑØ)\n-1\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.output_size","page":"Interface","title":"Bijectors.output_size","text":"output_size(f, sz)\n\nReturns the size of f(x) when given an input x of size sz.\n\n\n\n\n\noutput_size(f, dist::Distribution)\n\nReturns the output size of f given an input drawn from the distribution dist.\n\nBy default this just calls output_size(f, size(dist)), but this can be overloaded for specific distributions. This is useful when Base.size(dist) is not defined, e.g. for ProductNamedTupleDistribution and in particular is used by DynamicPPL when generating new random values for transformed distributions.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.transformed-Tuple{Distribution, Bijector}","page":"Interface","title":"Bijectors.transformed","text":"transformed(d::Distribution)\ntransformed(d::Distribution, b::Bijector)\n\nCouples distribution d with the bijector b by returning a TransformedDistribution.\n\nIf no bijector is provided, i.e. transformed(d) is called, then  transformed(d, bijector(d)) is returned.\n\n\n\n\n\n","category":"method"},{"location":"interface/#Bijectors.ordered","page":"Interface","title":"Bijectors.ordered","text":"ordered(d::Distribution)\n\nReturn a Distribution whose support are ordered vectors, i.e., vectors with increasingly ordered elements.\n\nSpecifically, d is restricted to the subspace of its domain containing only ordered elements.\n\nwarning: Warning\nrand is implemented using rejection sampling, which can be slow for high-dimensional distributions. In such cases, consider using MCMC methods to sample from the distribution instead.\n\nwarning: Warning\nThe resulting ordered distribution is un-normalized, which can cause issues in some contexts, e.g. in hierarchical models where the parameters of the ordered distribution are themselves sampled. See the notes below for a more detailed discussion.\n\nNotes on ordered being un-normalized\n\nThe resulting ordered distribution is un-normalized. This is not a problem if used in a context where the normalizing factor is irrelevant, but if the value of the normalizing factor impacts the resulting computation, the results may be inaccurate.\n\nFor example, if the distribution is used in sampling a posterior distribution with MCMC and the parameters of the ordered distribution are themselves sampled, then the normalizing factor would in general be needed for accurate sampling, and ordered should not be used. However, if the parameters are fixed, then since MCMC does not require distributions be normalized, ordered may be used without problems.\n\nA common case is where the distribution being ordered is a joint distribution of n identical univariate distributions. In this case the normalization factor works out to be the constant n!, and ordered can again be used without problems even if the parameters of the univariate distribution are sampled.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.isinvertible","page":"Interface","title":"Bijectors.isinvertible","text":"isinvertible(t)\n\nReturn true if t is invertible, and false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"interface/#Bijectors.isclosedform-Tuple{Bijectors.Transform}","page":"Interface","title":"Bijectors.isclosedform","text":"isclosedform(b::Transform)::bool\nisclosedform(b‚Åª¬π::Inverse{<:Transform})::bool\n\nReturns true or false depending on whether or not evaluation of b has a closed-form implementation.\n\nMost transformations have closed-form evaluations, but there are cases where this is not the case. For example the inverse evaluation of PlanarLayer requires an iterative procedure to evaluate.\n\n\n\n\n\n","category":"method"},{"location":"defining_examples/#Defining-a-bijector:-examples","page":"Defining a bijector: examples","title":"Defining a bijector: examples","text":"Here we provide two different worked examples of defining a custom bijector.","category":"section"},{"location":"defining_examples/#Cyclic-permutation","page":"Defining a bijector: examples","title":"Cyclic permutation","text":"We start with something simple: a bijector that performs a cyclic permutation of the elements of a vector.\n\nusing Bijectors\n\nstruct CircShift <: Bijector\n    shift::Int\nend\n\nAs described in the previous page, the only function you absolutely must implement is with_logabsdet_jacobian.\n\nLet's think for a moment about what the Jacobian is. CircShift is a mapping from ‚Ñù‚Åø ‚Üí ‚Ñù‚Åø that permutes the elements of the input vector. For example, CircShift(1) would map a length-3 vector x = [x1, x2, x3] to y = [x3, x1, x2].\n\nThat means that the Jacobian matrix is\n\nJ = beginbmatrix\npartial y_1partial x_1  partial y_1partial x_2  partial y_1partial x_3 \npartial y_2partial x_1  partial y_2partial x _2  partial y_2partial x_3 \npartial y_3partial x_1  partial y_3partial x_2  partial y_3partial x_3\nendbmatrix\n= beginbmatrix\n0  0  1 \n1  0  0 \n0  1  0\nendbmatrix\n\nIn general, the Jacobian of such a transformation is a permutation matrix. The determinant of a permutation matrix is either 1 or -1, depending on whether the permutation is even or odd. (In this case, it is even; but it could be odd for other shifts and/or input sizes.) This means that the log-absolute determinant of the Jacobian is always 0.\n\nWe can now implement with_logabsdet_jacobian.\n\nfunction Bijectors.with_logabsdet_jacobian(\n    b::CircShift, x::AbstractVector{T}\n) where {T<:Real}\n    y = circshift(x, b.shift)\n    return y, zero(T)\nend\n\nIt is good practice to let the type of the input determine the type of the log-Jacobian term here. However, you might also ask: since a cyclic permutation is also well-defined for arrays of non-real types, should we also allow that? We can do so by creating a new method, but we would have to make a choice as to the type of the log-Jacobian term, since we cannot derive it from the input type. Here, we will choose Float64:\n\nimport ChangesOfVariables: with_logabsdet_jacobian\n\nfunction with_logabsdet_jacobian(b::CircShift, x::AbstractVector)\n    y = circshift(x, b.shift)\n    return y, 0.0\nend\n\nWith this defined, we can now benefit from a host of automatic definitions:\n\nb = CircShift(1)\nx = [1.0, 2.0, 3.0]\nb(x)\n\nlogabsdetjac(b, x)\n\nWe can also define the inverse bijector. A default definition for inverse(b) already exists: it would return Bijectors.Inverse(b). But, if we used this default definition, we would have to also define with_logabsdet_jacobian(::Inverse{CircShift}, y). We can save ourselves this hassle by overloading the method:\n\nimport InverseFunctions: inverse\n\ninverse(b::CircShift) = CircShift(-b.shift)\n\nNow we can use the inverse bijector:\n\ny = b(x)\ninverse(b)(y) == x\n\nnote: Note\nBijectors re-exports both with_logabsdet_jacobian as well as inverse, so you don't need to import them separately if Bijectors is already a dependency. Conversely, if you don't want to depend on Bijectors.jl directly, you can just import these functions from their respective packages.","category":"section"},{"location":"defining_examples/#Stereographic-projection","page":"Defining a bijector: examples","title":"Stereographic projection","text":"Now, we'll look at a more complex example: a stereographic projection mapping points on the unit sphere (i.e., length-3 vectors x for which x_1^2 + x_2^2 + x_3^2 = 1), to points in the plane ‚Ñù¬≤ (i.e., length-2 vectors y whose elements are unconstrained).\n\nThe relevant formulae are given here on Wikipedia. The forward transform (from sphere to plane) is:\n\ny_1 = fracx_11 - x_3 qquad y_2 = fracx_21 - x_3\n\nusing Bijectors\n\nstruct StereographicProj <: Bijector end\nfunction (s::StereographicProj)(x::AbstractVector{T}) where {T<:Real}\n    y = similar(x, 2)\n    denom = one(T) - x[3]\n    y[1] = x[1] / denom\n    y[2] = x[2] / denom\n    return y\nend\n\nwarning: Warning\nThis will return [Inf, Inf] if x[3] == 1 (the 'north pole' of the sphere), which may potentially make downstream computations fail. One potential way around this is to add eps(T) to the denominator to avoid it ever being zero: you will sometimes see this trick used in Bijectors.jl. However, be aware that the reverse transform has to also be modified accordingly so that the two transforms remain inverses of each other!\n\nWhen it comes to computing the Jacobian, we find ourselves in a spot of bother. The partial derivatives themselves can ostensibly be computed using fairly straightforward calculus:\n\nJ = beginbmatrix\npartial y_1partial x_1  partial y_1partial x_2  partial y_1partial x_3 \npartial y_2partial x_1  partial y_2partial x_2  partial y_2partial x_3\nendbmatrix\n= beginbmatrix\n1(1 - x_3)  0  x_1(1 - x_3)^2 \n0  1(1 - x_3)  x_2(1 - x_3)^2\nendbmatrix\n\nbut since our mapping is from ‚Ñù¬≥ ‚Üí ‚Ñù¬≤, the Jacobian matrix is not square, and so we cannot compute its determinant!\n\nTo fix this, we need to realise that x_1, x_2, and x_3 are not really independent at all. The partial derivatives we computed above treated them as independent variables! In reality, they must satisfy the constraint x_1^2 + x_2^2 + x_3^2 = 1, which means that\n\nx_3 = pm sqrt1 - x_1^2 - x_2^2\n\nand thus\n\nfracpartial x_3partial x_1 = -fracx_1x_3 qquad fracpartial x_3partial x_2 = -fracx_2x_3\n\n(Note that this is true regardless of which sign x_3 has.)\n\nIn effect, we are treating x_3 as a function of x_1 and x_2, rather than as an independent variable. This means that we can construct a Jacobian using only x_1 and x_2 as inputs, and thus obtain a square Jacobian matrix.\n\nFor example, we can recompute the derivative of y_1 with respect to x_1, but this time also making sure to include the dependence of x_3 on x_1.\n\nbeginalign*\nfracpartial y_1partial x_1\n= fracpartialpartial x_1 x_1(1 - x_3)^-1 \n= (1 - x_3)^-1 + x_1 (-1)(1 - x_3)^-2 left(fracpartialpartial x_1(1 - x_3)right) \n= (1 - x_3)^-1 - x_1 (1 - x_3)^-2 left(fracx_1x_3right) \n= frac11 - x_3 - fracx_1^2x_3 (1 - x_3)^2\nendalign*\n\nA similar strategy for all the other partial derivatives gives us the Jacobian\n\nJ = beginbmatrix\ndfrac11 - x_3 - dfracx_1^2x_3 (1 - x_3)^2  -dfracx_1 x_2x_3 (1 - x_3)^2 \n-dfracx_1 x_2x_3 (1 - x_3)^2  dfrac11 - x_3 - dfracx_2^2x_3 (1 - x_3)^2\nendbmatrix\n\nnote: Note\nWhen you see x_3 here, don't think 'the variable x_3': it's just shorthand for pm sqrt1 - x_1^2 - x_2^2. (And recall that these formulae hold for both choices of sign.)\n\nIts determinant very nicely simplifies to\n\ndet(J) = -frac1x_3 (1 - x_3)^2\n\nthe absolute determinant being\n\ndet(J) = frac1x_3 (1 - x_3)^2\n\n((1 - x_3)^2 is always non-negative, of course); and thus\n\nfunction Bijectors.logabsdetjac(b::StereographicProj, x::AbstractVector{T}) where {T<:Real}\n    return -log(abs(x[3])) - (2 * log(one(T) - x[3]))\nend\n\nPhew!\n\nLet's take a moment and check that we did indeed do this correctly. To verify that the implementation of logabsdetjac is indeed correct, we can compare it against a Jacobian obtained via automatic differentiation.\n\nIf we try to calculate a Jacobian for StereographicProj(), we will just get a 2x3 matrix, which is not what we want. So, we need to take an extra step to map from the independent coordinates of x (i.e., x_1 and x_2) to the full 3D coordinates, and then to the plane:\n\nsgn = 1\n\nfunction full_transform(x12)\n    x3 = sgn * sqrt(one(eltype(x12)) - sum(x12 .^ 2))\n    x123 = vcat(x12, x3)\n    return StereographicProj()(x123)\nend\n\nimport DifferentiationInterface as DI\nusing FiniteDifferences, LinearAlgebra\nx = [0.3, 0.4, sgn * sqrt(1 - 0.3^2 - 0.4^2)]\n\nadtype = DI.AutoFiniteDifferences(; fdm=central_fdm(5, 1))\njac = DI.jacobian(full_transform, adtype, x[1:2])\nlogjac = logabsdet(jac)[1]\n\nHopefully this is approximately the same!\n\nlogabsdetjac(StereographicProj(), x)\n\nYou can also rerun the code blocks above with sgn = -1 to verify that our logabsdetjac implementation does indeed behave correctly for both positive and negative values of x_3.\n\nWhen writing unit tests for a new bijector, it is a good idea to include comparisons like this to verify that the Jacobian is computed correctly. The strategy used above to get square Jacobians is quite generally applicable, and is used for testing the bijectors for (e.g.) simplices and Cholesky factors.\n\nReturning to the Bijectors interface, because we have defined the forward transform as well as logabsdetjac, we can just use these to implement with_logabsdet_jacobian:\n\nfunction Bijectors.with_logabsdet_jacobian(s::StereographicProj, x)\n    return s(x), logabsdetjac(s, x)\nend\n\nOr if we wanted to be more efficient, we might notice that one(T) - x[3] is computed both in s(x) as well as in logabsdetjac. So we could also write:\n\nfunction Bijectors.with_logabsdet_jacobian(\n    s::StereographicProj, x::AbstractVector{T}\n) where {T<:Real}\n    denom = one(T) - x[3]  # Shared computation\n    y = similar(x, 2)\n    y[1] = x[1] / denom\n    y[2] = x[2] / denom\n    logjac = -log(abs(x[3])) - (2 * log(denom))\n    return y, logjac\nend\n\nOf course, this alone is unlikely to save any meaningful amount of time, but other bijectors may have more expensive computations that may be shared between both transform and log-Jacobian calculations.\n\nThe inverse bijector can be implemented in a very similar way (Wikipedia has the formulae as well), but is left as an exercise for the very willing reader!\n\nFinally, suppose we had a distribution UnitSphere, where rand(UnitSphere()) returned a random point on the unit sphere. Something similar to this technically exists in Manifolds.jl, but we can also define a hacky version ourselves:\n\nusing Distributions\n\nstruct UnitSphere <: Distributions.ContinuousMultivariateDistribution end\nBase.size(::UnitSphere) = (3,)\nBase.rand(::UnitSphere) = normalize(rand(3))\n\nThen, we could define\n\nBijectors.bijector(::UnitSphere) = StereographicProj()\n\n# Not strictly needed for this example, but other usage may require it\nBijectors.output_size(::StereographicProj, ::UnitSphere) = (2,)\n\nand that would allow us to construct, for example, transformed distributions:\n\ntd = transformed(UnitSphere())\nrand(td)  # returns a random point in ‚Ñù¬≤\n\nWe didn't define logpdf for UnitSphere, but if we had, then we would also be able to make use of logpdf(td, y) and Bijectors.logpdf_with_trans.","category":"section"},{"location":"distributions/#Usage-with-distributions","page":"Usage with distributions","title":"Usage with distributions","text":"Bijectors provides many utilities for working with probability distributions.\n\nusing Bijectors\n\ndist = LogNormal()\nx = rand(dist)\nb = bijector(dist)  # bijection (0, ‚àû) ‚Üí ‚Ñù\n\ny = b(x)\n\nHere, bijector(d::Distribution) returns the corresponding constrained-to-unconstrained bijection for Beta, which is a log function. The resulting bijector can be called, just like any other function, to transform samples from the distribution to the unconstrained space.\n\nThe function link provides a short way of doing the above:\n\nlink(dist, x) ‚âà b(x)\n\nSee the Turing.jl docs for more information about how this is used in probabilistic programming.","category":"section"},{"location":"distributions/#Transforming-distributions","page":"Usage with distributions","title":"Transforming distributions","text":"We can also couple a distribution together with its bijector to create a transformed Distribution, i.e. a Distribution defined by sampling from a given Distribution and then transforming using a given transformation:\n\ndist = LogNormal()          # support on (0, ‚àû)\ntdist = transformed(dist)   # support on ‚Ñù\n\nWe can then sample from, and compute the logpdf for, the resulting distribution:\n\ny = rand(tdist)\n\nlogpdf(tdist, y)\n\nWe should expect here that\n\nlogpdf(tdist, y) ‚âà logpdf(dist, x) - logabsdetjac(b, x)\n\nwhere b = bijector(dist) and y = b(x).\n\nTo verify this, we can calculate the value of x using the inverse bijector:\n\nb = bijector(dist)\nbinv = inverse(b)\n\nx = binv(y)\n\n(Because b is just a log function, binv is an exponential function, i.e. x = exp(y).)\n\nThen we can check the equality:\n\nlogpdf(tdist, y) ‚âà logpdf(dist, x) - logabsdetjac(b, x)\n\nYou can also use Bijectors.logpdf_with_trans with the original distribution:\n\nlogpdf_with_trans(dist, x, false) ‚âà logpdf(dist, x)\n\nlogpdf_with_trans(dist, x, true) ‚âà logpdf(tdist, y)","category":"section"},{"location":"advi/#Example:-Variational-inference","page":"Example: Variational inference","title":"Example: Variational inference","text":"The real utility of TransformedDistribution becomes more apparent when using transformed(dist, b) for any bijector b. To get the transformed distribution corresponding to the Beta(2, 2), we called transformed(dist) before. This is an alias for transformed(dist, bijector(dist)). Remember bijector(dist) returns the constrained-to-constrained bijector for that particular Distribution. But we can of course construct a TransformedDistribution using different bijectors with the same dist.\n\nThis is particularly useful in Automatic Differentiation Variational Inference (ADVI).","category":"section"},{"location":"advi/#Univariate-ADVI","page":"Example: Variational inference","title":"Univariate ADVI","text":"An important part of ADVI is to approximate a constrained distribution, e.g. Beta, as follows:\n\nSample x from a Normal with parameters Œº and œÉ, i.e. x ~ Normal(Œº, œÉ).\nTransform x to y s.t. y ‚àà support(Beta), with the transform being a differentiable bijection with a differentiable inverse (a \"bijector\").\n\nThis then defines a probability density with the same support as Beta! Of course, it's unlikely that it will be the same density, but it's an approximation.\n\nCreating such a distribution can be done with Bijector and TransformedDistribution:\n\nusing Bijectors\nusing StableRNGs: StableRNG\nrng = StableRNG(42)\n\ndist = Beta(2, 2)\nb = bijector(dist)                # (0, 1) ‚Üí ‚Ñù\nb‚Åª¬π = inverse(b)                  # ‚Ñù ‚Üí (0, 1)\ntd = transformed(Normal(), b‚Åª¬π)   # x ‚àº ùìù(0, 1) then b(x) ‚àà (0, 1)\nx = rand(rng, td)                 # ‚àà (0, 1)\n\nIt's worth noting that support(Beta) is the closed interval [0, 1], while the constrained-to-unconstrained bijection, Logit in this case, is only well-defined as a map (0, 1) ‚Üí ‚Ñù for the open interval (0, 1). This is of course not an implementation detail. ‚Ñù is itself open, thus no continuous bijection exists from a closed interval to ‚Ñù. But since the boundaries of a closed interval has what's known as measure zero, this doesn't end up affecting the resulting density with support on the entire real line. In practice, this means that\n\ntd = transformed(Beta())\ninverse(td.transform)(rand(rng, td))\n\nwill never result in 0 or 1 though any sample arbitrarily close to either 0 or 1 is possible. Disclaimer: numerical accuracy is limited, so you might still see 0 and 1 if you're 'lucky'.","category":"section"},{"location":"advi/#Multivariate-ADVI-example","page":"Example: Variational inference","title":"Multivariate ADVI example","text":"We can also do multivariate ADVI using the Stacked bijector. Stacked gives us a way to combine univariate and/or multivariate bijectors into a singe multivariate bijector. Say you have a vector x of length 2 and you want to transform the first entry using Exp and the second entry using Log. Stacked gives you an easy and efficient way of representing such a bijector.\n\nusing Bijectors: SimplexBijector\n\n# Original distributions\ndists = (Beta(), InverseGamma(), Dirichlet(2, 3))\n\n# Construct the corresponding ranges\nfunction make_ranges(dists)\n    ranges = []\n    idx = 1\n    for i in 1:length(dists)\n        d = dists[i]\n        push!(ranges, idx:(idx + length(d) - 1))\n        idx += length(d)\n    end\n    return ranges\nend\n\nranges = make_ranges(dists)\nranges\n\n# Base distribution; mean-field normal\nnum_params = ranges[end][end]\n\nd = MvNormal(zeros(num_params), ones(num_params));\n\n# Construct the transform\nbs = bijector.(dists)       # constrained-to-unconstrained bijectors for dists\nibs = inverse.(bs)          # invert, so we get unconstrained-to-constrained\nsb = Stacked(ibs, ranges)   # => Stacked <: Bijector\n\n# Mean-field normal with unconstrained-to-constrained stacked bijector\ntd = transformed(d, sb)\ny = rand(td)\n\nAs can be seen from this, we now have a y for which 0.0 ‚â§ y[1] ‚â§ 1.0, 0.0 < y[2], and sum(y[3:4]) ‚âà 1.0.","category":"section"},{"location":"#Bijectors.jl","page":"Bijectors.jl","title":"Bijectors.jl","text":"This package implements functionality for transforming random variables to Euclidean space (and back).\n\nFor example, consider a random variable X sim mathrmBeta(2 2), which has support on (0 1):\n\nusing Bijectors\n\nx = rand(Beta(2, 2))\n\nIn this case, the logit function is used as the transformation:\n\nY = mathrmlogit(X) = logleft(fracX1 - Xright)\n\nWe can construct this function\n\nb = bijector(Beta(2, 2))\n\nand apply it to x:\n\ny = b(x)\n\nYou can also obtain the log absolute determinant of the Jacobian of the transformation:\n\ny, ladj = with_logabsdet_jacobian(b, x)","category":"section"},{"location":"defining/#Defining-a-bijector","page":"Defining a bijector","title":"Defining a bijector","text":"This page describes the minimum expected interface to implement a bijector.\n\nIn general, there are two pieces of information needed to define a bijector:\n\nThe transformation itself, i.e., the map b mathbbR^d to mathbbR^d.\nThe log-absolute determinant of the Jacobian of that transformation. For a transformation b mathbbR^d to mathbbR^d, the Jacobian at point x in mathbbR^d is defined as:\nJ_b(x) = beginbmatrix\npartial y_1partial x_1  partial y_1partial x_2  cdots  partial y_1partial x_d \npartial y_2partial x_1  partial y_2partial x_2  cdots  partial y_2partial x_d \nvdots  vdots  ddots  vdots \npartial y_dpartial x_1  partial y_dpartial x_2  cdots  partial y_dpartial x_d\nendbmatrix\nwhere y = b(x).","category":"section"},{"location":"defining/#The-transform-itself","page":"Defining a bijector","title":"The transform itself","text":"The most efficient way to implement a bijector is to provide an implementation of:\n\nnote: Note\nwith_logabsdet_jacobian is re-exported from ChangesOfVariables.jl, so if you want to avoid importing Bijectors.jl, you can implement ChangesOfVariables.with_logabsdet_jacobian instead.\n\nIf you define with_logabsdet_jacobian(b, x), then you will automatically get default implementations of both transform(b, x) and logabsdetjac(b, x), which respectively return the first and second value of that tuple. So, in fact, you can implement a bijector by defining only with_logabsdet_jacobian.\n\nIf you prefer, you can implement transform and logabsdetjac separately, as described below. Having manual implementations of these may also be useful if you expect either to be used heavily without the other.","category":"section"},{"location":"defining/#Transformation","page":"Defining a bijector","title":"Transformation","text":"If transform(b, x) is defined, then you will automatically get a default implementation of b(x) which calls that.","category":"section"},{"location":"defining/#Log-absolute-determinant-of-the-Jacobian","page":"Defining a bijector","title":"Log-absolute determinant of the Jacobian","text":"","category":"section"},{"location":"defining/#Inverse","page":"Defining a bijector","title":"Inverse","text":"Often you will want to define an inverse bijector as well. To do so, you will have to implement:\n\nnote: Note\ninverse is re-exported from InverseFunctions.jl, so the same note as for with_logabsdet_jacobian applies.\n\nIf b is a bijector, then inverse(b) should return the inverse bijector b^-1.\n\nIf your bijector subtypes Bijectors.Bijector, then you will get a default implementation of inverse which constructs Bijectors.Inverse(b). This may be easier than creating a second type for the inverse bijector. Note that you will also need to implement the methods for with_logabsdet_jacobian (and/or transform and logabsdetjac) for the inverse bijector type.\n\nIf your bijector is not invertible, you can specify this here:","category":"section"},{"location":"defining/#Distributions","page":"Defining a bijector","title":"Distributions","text":"If your bijector is intended for use with a distribution, i.e., it transforms random variables drawn from that distribution to Euclidean space, then you should also implement:\n\nwhich should return your bijector.\n\nOn top of that, you should also implement a method for Bijectors.output_size(b, dist::Distribution):","category":"section"},{"location":"defining/#Closed-form","page":"Defining a bijector","title":"Closed-form","text":"If your bijector does not have a closed-form expression (e.g. if it uses an iterative procedure), then this should be set to false:\n\nThe default is true so you only need to set this if your bijector is not closed-form.","category":"section"},{"location":"defining/#ChangesOfVariables.with_logabsdet_jacobian-defining","page":"Defining a bijector","title":"ChangesOfVariables.with_logabsdet_jacobian","text":"with_logabsdet_jacobian(t::Transform, x)\n\nSemantically, this must return a tuple of (y, logabsdetjac), where y = transform(t, x) and logabsdetjac = logabsdetjac(t, x). However, you can implement this function to exploit shared computation between the two quantities.\n\n\n\n\n\n","category":"function"},{"location":"defining/#Bijectors.transform-defining","page":"Defining a bijector","title":"Bijectors.transform","text":"transform(b, x)\n\nTransform x using b.\n\nIf with_logabsdet_jacobian is already implemented for b, the default implementation of transform will call first(with_logabsdet_jacobian(b, x)).\n\n\n\n\n\n","category":"function"},{"location":"defining/#Bijectors.logabsdetjac-defining","page":"Defining a bijector","title":"Bijectors.logabsdetjac","text":"logabsdetjac(b, x)\n\nReturn log(abs(det(J(b, x)))), where J(b, x) is the jacobian of b at x.\n\n\n\n\n\n","category":"function"},{"location":"defining/#InverseFunctions.inverse-defining","page":"Defining a bijector","title":"InverseFunctions.inverse","text":"inverse(t::Transform)\n\nReturns the inverse of transform t.\n\n\n\n\n\n","category":"function"},{"location":"defining/#Bijectors.isinvertible-defining","page":"Defining a bijector","title":"Bijectors.isinvertible","text":"isinvertible(t)\n\nReturn true if t is invertible, and false otherwise.\n\n\n\n\n\n","category":"function"},{"location":"defining/#Bijectors.bijector-defining","page":"Defining a bijector","title":"Bijectors.bijector","text":"bijector(d::Distribution)\n\nReturns the constrained-to-unconstrained bijector for distribution d.\n\n\n\n\n\n","category":"function"},{"location":"defining/#Bijectors.output_size-defining","page":"Defining a bijector","title":"Bijectors.output_size","text":"output_size(f, sz)\n\nReturns the size of f(x) when given an input x of size sz.\n\n\n\n\n\noutput_size(f, dist::Distribution)\n\nReturns the output size of f given an input drawn from the distribution dist.\n\nBy default this just calls output_size(f, size(dist)), but this can be overloaded for specific distributions. This is useful when Base.size(dist) is not defined, e.g. for ProductNamedTupleDistribution and in particular is used by DynamicPPL when generating new random values for transformed distributions.\n\n\n\n\n\n","category":"function"},{"location":"defining/#Bijectors.isclosedform-defining","page":"Defining a bijector","title":"Bijectors.isclosedform","text":"isclosedform(b::Transform)::bool\nisclosedform(b‚Åª¬π::Inverse{<:Transform})::bool\n\nReturns true or false depending on whether or not evaluation of b has a closed-form implementation.\n\nMost transformations have closed-form evaluations, but there are cases where this is not the case. For example the inverse evaluation of PlanarLayer requires an iterative procedure to evaluate.\n\n\n\n\n\n","category":"function"}]
}
